{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31fa0ecb-172f-47df-b36e-257e65b879af",
   "metadata": {},
   "source": [
    "This notebook is the process of creating the automatically constructed ontology without clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e77e1f6-d307-484c-98fa-881e79f673b9",
   "metadata": {},
   "source": [
    "Pre-processing of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd5f5e4c-0d6a-433e-bb4d-05964371a6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "import nltk\n",
    "from word2number import w2n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f982f654-1861-4c2a-8d71-e107bb6c001a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Removing time measures from endpoint data\n",
    "def remove_time_measures(text):\n",
    "    time_units = ['day', 'week', 'month', 'year']\n",
    "    time_units += [unit + 's' for unit in time_units]\n",
    "    pattern = r'\\b\\d*\\s*(' + '|'.join(time_units) + r')\\b'\n",
    "    new_text = re.sub(pattern, '', text)\n",
    "    new_text = re.sub(r'\\d-\\s', '', new_text)\n",
    "    \n",
    "    return new_text\n",
    "\n",
    "# Converting the word representation of numbers into integers\n",
    "def word_to_num(text):\n",
    "    words = text.split()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        try:\n",
    "            number = w2n.word_to_num(word)\n",
    "            new_words.append(str(number))\n",
    "        except ValueError:\n",
    "            new_words.append(word)\n",
    "    new_text = ' '.join(new_words)\n",
    "    return new_text\n",
    "\n",
    "#Remove the last word until the endpoint ends with a noun\n",
    "def remove_until_noun(text):\n",
    "    words = text.split()\n",
    "    while len(words) > 1:\n",
    "        pos = nltk.pos_tag(words)\n",
    "        last_word, last_pos = pos[-1]\n",
    "        if last_pos.startswith('NN'):\n",
    "            break\n",
    "        else:\n",
    "            words = words[:-1]\n",
    "    new_text = ' '.join(words)\n",
    "    return new_text\n",
    "\n",
    "def process_text(text):\n",
    "    text = word_to_num(text)\n",
    "    text = remove_time_measures(text)\n",
    "    text = remove_until_noun(text)\n",
    "    return text\n",
    "\n",
    "#Split the endpoints by the first ',', ':' or \"(\"\n",
    "def extract_keywords(sentence, max_words=30):\n",
    "    words = sentence.split(\",\")\n",
    "    words_before_colon = words[0]\n",
    "    if \":\" in words_before_colon:\n",
    "        words_after_colon = re.sub(r'\\([^)]*\\)', '', words_before_colon.split(\":\")[1])\n",
    "        filtered_words = [w.strip() for w in words_after_colon.lower().split()][:max_words]\n",
    "    elif \"(\" in words_before_colon:\n",
    "        words_before_bracket = words_before_colon.split(\"(\")[0]\n",
    "        filtered_words = [w.strip() for w in words_before_bracket.lower().split()][:max_words]\n",
    "    else:\n",
    "        filtered_words = [w.strip() for w in words_before_colon.lower().split()][:max_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "\n",
    "df = pd.read_csv('ctg-studies.csv')\n",
    "outcome_measures = df.iloc[:300, 2]\n",
    "\n",
    "# Removing duplicates\n",
    "outcome_measures.dropna(inplace=True)\n",
    "\n",
    "outcome_measures_keywords = outcome_measures.apply(lambda x: extract_keywords(str(x)))\n",
    "\n",
    "outcome_measures_processed = outcome_measures_keywords.apply(process_text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0295df47-1730-4f22-bc26-25761b70edc5",
   "metadata": {},
   "source": [
    "This extracts the pre-processed outcome measures into a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77cca6c8-3f2a-4da0-92d1-4c30fc21e096",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('outcome_measures.txt', 'w', encoding='utf-8') as f:\n",
    "    for measure in outcome_measures_processed:\n",
    "        # write each measure on a new line\n",
    "        f.write(measure + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5f27f3-7315-4eb4-8148-55aaafb6b90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Importing the text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "967e7349-bbab-4111-b722-246bae98630a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "\n",
    "with open('ai_processed_measures.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        sentence = line.rstrip('.\\n')  \n",
    "        sentences.append(sentence)\n",
    "\n",
    "sentences = list(set(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bfc481-a2ab-4073-a727-b1dcf3d363be",
   "metadata": {},
   "source": [
    "Sentence embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "133af6a9-a62c-43ef-bbd1-49c6e2c91028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the predefined labels\n",
    "labels = [\"Measure of quality of life\",\n",
    "    \"Measure of patient satisfaction\",\n",
    "    \"Measure of tolerability\",\n",
    "    \"Measure of adherence\",\n",
    "    \"Measure of costs\",\n",
    "    \"Measure of efficacy\",\n",
    "    \"Measure of healthcare resource utilization\",\n",
    "    \"Measure of neurocognitive function\",\n",
    "    \"Measure of nutritional status\",\n",
    "    \"Measure of patient preference\",\n",
    "    \"Measure of performance status\",\n",
    "    \"Measure of sexual function\",\n",
    "    \"Measure of safety\"]\n",
    "\n",
    "\n",
    "# Cluster the data using sentence embeddings and hierarchial clustering\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "outcome_measures = sentences  # Convert the outcome measure sentences to a list\n",
    "sentence_embeddings = model.encode(outcome_measures)\n",
    "Z = linkage(sentence_embeddings, metric='cosine', method='average')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dca7ca-8a27-4536-a84d-b69e08f16ac0",
   "metadata": {},
   "source": [
    "Cutoff point is at 0.0, so no clustering of endpoints will be performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f346a6c-9f2b-4919-83c9-4d2716faa4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_height = 0.0  \n",
    "clusters = fcluster(Z, t=cutoff_height, criterion='distance')\n",
    "\n",
    "outcome_measures_clustered = pd.DataFrame({'Outcome Measure': outcome_measures, 'Cluster': clusters})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381c692f-f3a7-4249-8c3f-a1ed46d9f261",
   "metadata": {},
   "source": [
    "Topic modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b4f829-e556-4580-94df-d6b007260b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for LDA\n",
    "vectorizer_outcome = CountVectorizer()\n",
    "vectorizer_labels = CountVectorizer()\n",
    "\n",
    "X_outcome = vectorizer_outcome.fit_transform(outcome_measures)\n",
    "X_labels = vectorizer_labels.fit_transform(labels)\n",
    "\n",
    "# Fit LDA models\n",
    "lda_model_outcome = LatentDirichletAllocation(n_components=13, random_state=0)\n",
    "lda_model_outcome.fit(X_outcome)\n",
    "topics = lda_model_outcome.transform(X_outcome)\n",
    "\n",
    "lda_model_labels = LatentDirichletAllocation(n_components=len(labels), random_state=0)  # assuming each label represents a different topic\n",
    "lda_model_labels.fit(X_labels)\n",
    "\n",
    "# Extract keywords from outcome measures\n",
    "feature_names_outcome = vectorizer_outcome.get_feature_names_out()\n",
    "keywords_per_topic_outcome = []\n",
    "for topic_idx, topic in enumerate(lda_model_outcome.components_):\n",
    "    keywords_per_topic_outcome.append([feature_names_outcome[i] for i in topic.argsort()[:-6:-1]])\n",
    "\n",
    "# Extract keywords from labels\n",
    "feature_names_labels = vectorizer_labels.get_feature_names_out()\n",
    "keywords_per_topic_labels = []\n",
    "for topic_idx, topic in enumerate(lda_model_labels.components_):\n",
    "    keywords_per_topic_labels.append([feature_names_labels[i] for i in topic.argsort()[:-6:-1]])\n",
    "\n",
    "# Calculate similarity between the extracted keywords from outcomes and labels\n",
    "similarity_scores_per_cluster = []\n",
    "for cluster_id in outcome_measures_clustered['Cluster'].unique():\n",
    "    cluster_topic_idx = topics[outcome_measures_clustered[outcome_measures_clustered['Cluster'] == cluster_id].index[0]].argmax()\n",
    "    cluster_keywords = keywords_per_topic_outcome[cluster_topic_idx]\n",
    "    cluster_keywords_embedding = model.encode(cluster_keywords)\n",
    "    cluster_keywords_embedding_mean = np.mean(cluster_keywords_embedding, axis=0)\n",
    "    \n",
    "    label_similarity_scores = []\n",
    "    for label_keywords in keywords_per_topic_labels:\n",
    "        label_keywords_embedding = model.encode(label_keywords)\n",
    "        label_keywords_embedding_mean = np.mean(label_keywords_embedding, axis=0)\n",
    "        label_similarity_scores.append(cosine_similarity([cluster_keywords_embedding_mean], [label_keywords_embedding_mean])[0][0])\n",
    "\n",
    "    similarity_scores_per_cluster.append(label_similarity_scores)\n",
    "\n",
    "# Assign labels based on the highest similarity score and a threshold of 0.5\n",
    "label_threshold = 0.5\n",
    "\n",
    "labels_per_outcome = []\n",
    "for cluster_id in outcome_measures_clustered['Cluster']:\n",
    "    similarity_scores = np.array(similarity_scores_per_cluster[cluster_id-1])\n",
    "    max_score_idx = similarity_scores.argmax()\n",
    "    max_score = similarity_scores[max_score_idx]\n",
    "    if max_score > label_threshold:\n",
    "        labels_per_outcome.append(labels[max_score_idx])\n",
    "\n",
    "# Add the labels column to the outcome_measures_clustered dataframe\n",
    "outcome_measures_clustered['Label'] = labels_per_outcome\n",
    "\n",
    "# Merge the clusters using the pandas concat function\n",
    "merged_clusters = pd.concat([outcome_measures_clustered.groupby('Label')['Outcome Measure'].agg(list), outcome_measures_clustered.groupby('Label').size()], axis=1).reset_index()\n",
    "merged_clusters.columns = ['Label', 'Outcome Measure', 'Size']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611f6839-f4b4-45ee-85bf-bea64518cbe3",
   "metadata": {},
   "source": [
    "Exporting it as an ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a387f7-4217-4ee3-99ca-7b5566dae305",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Warning: optimized Cython parser module 'owlready2_optimized' is not available, defaulting to slower Python implementation\n"
     ]
    }
   ],
   "source": [
    "from owlready2 import *\n",
    "import types\n",
    "import re\n",
    "\n",
    "# Create a new ontology\n",
    "ontology = get_ontology(\"http://example.com/ontologynoc.owl\")\n",
    "\n",
    "# List of desired class labels\n",
    "desired_labels = [\n",
    "    \"Measure of quality of life\",\n",
    "    \"Measure of patient satisfaction\",\n",
    "    \"Measure of tolerability\",\n",
    "    \"Measure of adherence\",\n",
    "    \"Measure of costs\",\n",
    "    \"Measure of efficacy\",\n",
    "    \"Measure of healthcare resource utilization\",\n",
    "    \"Measure of neurocognitive function\",\n",
    "    \"Measure of nutritional status\",\n",
    "    \"Measure of patient preference\",\n",
    "    \"Measure of performance status\",\n",
    "    \"Measure of sexual function\",\n",
    "    \"Measure of safety\",\n",
    "]\n",
    "\n",
    "with ontology:\n",
    "    # For each desired label\n",
    "    for label in desired_labels:\n",
    "        # Clean up the label name to be a valid class name\n",
    "        label_class_name = re.sub('\\W|^(?=\\d)','_', label)\n",
    "        # Create a new OWL class for this label\n",
    "        LabelClass = types.new_class(label_class_name, (Thing,))\n",
    "        # Append original label name as rdfs:label\n",
    "        LabelClass.label.append(label)\n",
    "        # Get the outcome measures for this label\n",
    "        cluster_outcomes = merged_clusters[merged_clusters['Label'] == label]['Outcome Measure']\n",
    "        # For each outcome measure list\n",
    "        for outcome_list in cluster_outcomes:\n",
    "            # For each outcome in the list\n",
    "            for outcome in outcome_list:\n",
    "                # Clean up the outcome name to be a valid class name\n",
    "                outcome_class_name = re.sub('\\W|^(?=\\d)','_', outcome)\n",
    "                # Create a new OWL class for this outcome measure, as a subclass of LabelClass\n",
    "                OutcomeClass = types.new_class(outcome_class_name, (LabelClass,))\n",
    "                # Append original outcome name as rdfs:label\n",
    "                OutcomeClass.label.append(outcome)\n",
    "\n",
    "# Save the ontology to an OWL file\n",
    "ontology.save(file = \"non_clustered_ontology2.owl\", format = \"rdfxml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db194e43-9eaf-4cbf-825c-e712ddc14691",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
